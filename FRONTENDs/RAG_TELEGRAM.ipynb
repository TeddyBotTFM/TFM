{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fae284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código está disponible en formato .ipynb para facilitar la comprensión y la ejecución en entornos locales.\n",
    "#Si se desea implementar en un servidor online, es necesario convertir los archivos a formato .py para su ejecución.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "import telebot\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa el bot de Telegram con el token desde las variables de entorno\n",
    "bot = telebot.TeleBot(os.getenv(\"TELEGRAM_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8667b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mensajes de contexto inicial para ChatOpenAI\n",
    "messages = [\n",
    "        SystemMessage(content=\"You are a motivational assistant with a warm and informal tone. Your primary focus is to provide motivation and encouragement. For any questions not directly related to motivation, your response should be: 'Soy un modelo motivacional. Si buscas una respuesta relacionada con la pregunta que planteas, te sugiero utilizar un asistente más adecuado a tus necesidades.' Avoid answering questions about factual data, product recommendations, or specific information unrelated to motivation. Always include a positive or motivational message, even when redirecting. If you don´t find anything in source_knowledge you have to answer 'Lo siento no dispongo de información al respecto'.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great, thank you! I'm here to motivate and inspire you. How can I help you feel more empowered today?\"),\n",
    "    HumanMessage(content=\"I'd like to know how to be happy.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61912c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del cliente Qdrant con las variables de entorno\n",
    "qdrant = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9aab1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Configuración del modelo de embeddings\n",
    "embeddings_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be189177",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Función para construir el prompt y manejar la consulta\n",
    "def custom_prompt(query: str, collection_name: str):\n",
    "    # Generación del embedding de la consulta\n",
    "    query_embedding = embeddings_model.encode([query])[0].tolist()\n",
    "\n",
    "    # Búsqueda en Qdrant\n",
    "    results = qdrant.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=3\n",
    "    )\n",
    "\n",
    "    # Extracción del texto de la carga útil\n",
    "    source_knowledge = \"\\n\".join([result.payload.get(\"text\", \"No text available\") for result in results])\n",
    "\n",
    "    # Construcción del prompt aumentado\n",
    "    augment_prompt = f\"\"\"Using the contexts below, answer the query:\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "\n",
    "    return augment_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73231dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Función principal para manejar las consultas (sin ponderación, solo con y sin stopwords)\n",
    "def handle_query(query: str, use_stopwords: bool):\n",
    "    collection_name = \"OnlyContent_withStopwords\" if use_stopwords else \"OnlyContent_withoutStopwords\"\n",
    "    prompt = HumanMessage(content=custom_prompt(query, collection_name))\n",
    "    messages.append(prompt)\n",
    "    res = chat.invoke(messages)\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31b453",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Manejo del comando '/start' en Telegram\n",
    "@bot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"¡Hola! Soy Teddy, tu bot motivacional.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51867efa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Manejo de mensajes de texto en Telegram\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def echo_message(message):\n",
    "    query = message.text\n",
    "    response = handle_query(query, use_stopwords=True)  # Usamos la BBDD con stopwords\n",
    "    bot.reply_to(message, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantiene el bot en funcionamiento\n",
    "bot.infinity_polling()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
